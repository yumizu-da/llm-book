{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPd9M8z8Xuuz"
      },
      "source": [
        "# 第10章 性能評価"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sIoOf50YMPy"
      },
      "source": [
        "## 10.3 LLMを用いた自動評価"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9G0hylSYMZX"
      },
      "source": [
        "### 10.3.2 Japanese Vicuna QA Benchmarkによる自動評価"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6euRGsq9YMfZ"
      },
      "source": [
        "#### ツールを使用した評価"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoXgBqZNST0Y",
        "outputId": "90934635-eb37-4dd2-936e-1464c5903029"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flexeval in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.43.3)\n",
            "Requirement already satisfied: datasets<3.0.0,>=2.14.6 in /usr/local/lib/python3.10/dist-packages (from flexeval) (2.20.0)\n",
            "Requirement already satisfied: evaluate<0.5.0,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from flexeval) (0.4.2)\n",
            "Requirement already satisfied: fuzzywuzzy<0.19.0,>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from flexeval) (0.18.0)\n",
            "Requirement already satisfied: google-api-python-client<3.0.0,>=2.131.0 in /usr/local/lib/python3.10/dist-packages (from flexeval) (2.137.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from flexeval) (3.1.4)\n",
            "Requirement already satisfied: jiwer<4.0.0,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from flexeval) (3.0.4)\n",
            "Requirement already satisfied: jsonargparse<5.0.0,>=4.26.1 in /usr/local/lib/python3.10/dist-packages (from jsonargparse[jsonnet]<5.0.0,>=4.26.1->flexeval) (4.32.0)\n",
            "Requirement already satisfied: loguru<0.8.0,>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from flexeval) (0.7.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.16.1 in /usr/local/lib/python3.10/dist-packages (from flexeval) (1.40.3)\n",
            "Requirement already satisfied: peft<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from flexeval) (0.10.0)\n",
            "Requirement already satisfied: python-levenshtein<0.24.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from flexeval) (0.23.0)\n",
            "Requirement already satisfied: rouge<2.0.0,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from flexeval) (1.0.1)\n",
            "Requirement already satisfied: sacrebleu<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from sacrebleu[ja]<3.0.0,>=2.4.1->flexeval) (2.4.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.1 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]<5.0.0,>=4.34.1->flexeval) (4.42.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.6->flexeval) (3.15.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.6->flexeval) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.6->flexeval) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.6->flexeval) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.6->flexeval) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.6->flexeval) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.6->flexeval) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.6->flexeval) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.6->flexeval) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets<3.0.0,>=2.14.6->flexeval) (2024.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.6->flexeval) (3.10.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.6->flexeval) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.6->flexeval) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.6->flexeval) (6.0.2)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client<3.0.0,>=2.131.0->flexeval) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client<3.0.0,>=2.131.0->flexeval) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client<3.0.0,>=2.131.0->flexeval) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client<3.0.0,>=2.131.0->flexeval) (2.19.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client<3.0.0,>=2.131.0->flexeval) (4.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.2->flexeval) (2.1.5)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer<4.0.0,>=3.0.4->flexeval) (8.1.7)\n",
            "Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.10/dist-packages (from jiwer<4.0.0,>=3.0.4->flexeval) (3.9.6)\n",
            "Requirement already satisfied: jsonnet>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from jsonargparse[jsonnet]<5.0.0,>=4.26.1->flexeval) (0.20.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.16.1->flexeval) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.16.1->flexeval) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.16.1->flexeval) (0.27.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.16.1->flexeval) (0.5.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.16.1->flexeval) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.16.1->flexeval) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.16.1->flexeval) (4.12.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft<0.11.0,>=0.10.0->flexeval) (5.9.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft<0.11.0,>=0.10.0->flexeval) (0.32.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft<0.11.0,>=0.10.0->flexeval) (0.4.4)\n",
            "Requirement already satisfied: Levenshtein==0.23.0 in /usr/local/lib/python3.10/dist-packages (from python-levenshtein<0.24.0,>=0.23.0->flexeval) (0.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge<2.0.0,>=1.0.1->flexeval) (1.16.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3.0.0,>=2.4.1->sacrebleu[ja]<3.0.0,>=2.4.1->flexeval) (2.10.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3.0.0,>=2.4.1->sacrebleu[ja]<3.0.0,>=2.4.1->flexeval) (2024.5.15)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3.0.0,>=2.4.1->sacrebleu[ja]<3.0.0,>=2.4.1->flexeval) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3.0.0,>=2.4.1->sacrebleu[ja]<3.0.0,>=2.4.1->flexeval) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3.0.0,>=2.4.1->sacrebleu[ja]<3.0.0,>=2.4.1->flexeval) (4.9.4)\n",
            "Requirement already satisfied: mecab-python3<=1.0.6,>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from sacrebleu[ja]<3.0.0,>=2.4.1->flexeval) (1.0.6)\n",
            "Requirement already satisfied: ipadic<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from sacrebleu[ja]<3.0.0,>=2.4.1->flexeval) (1.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.6.20)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.1->transformers[ja,sentencepiece,torch]<5.0.0,>=4.34.1->flexeval) (0.19.1)\n",
            "Requirement already satisfied: fugashi>=1.0 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]<5.0.0,>=4.34.1->flexeval) (1.3.2)\n",
            "Requirement already satisfied: rhoknp<1.3.1,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]<5.0.0,>=4.34.1->flexeval) (1.3.0)\n",
            "Requirement already satisfied: sudachidict-core>=20220729 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]<5.0.0,>=4.34.1->flexeval) (20240716)\n",
            "Requirement already satisfied: sudachipy>=0.6.6 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]<5.0.0,>=4.34.1->flexeval) (0.6.8)\n",
            "Requirement already satisfied: unidic>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]<5.0.0,>=4.34.1->flexeval) (1.1.0)\n",
            "Requirement already satisfied: unidic-lite>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]<5.0.0,>=4.34.1->flexeval) (1.0.8)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]<5.0.0,>=4.34.1->flexeval) (3.20.3)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[ja,sentencepiece,torch]<5.0.0,>=4.34.1->flexeval) (0.1.99)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.16.1->flexeval) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.16.1->flexeval) (1.2.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.6->flexeval) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.6->flexeval) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.6->flexeval) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.6->flexeval) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.6->flexeval) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.6->flexeval) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.6->flexeval) (4.0.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client<3.0.0,>=2.131.0->flexeval) (1.63.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client<3.0.0,>=2.131.0->flexeval) (1.24.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client<3.0.0,>=2.131.0->flexeval) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client<3.0.0,>=2.131.0->flexeval) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client<3.0.0,>=2.131.0->flexeval) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client<3.0.0,>=2.131.0->flexeval) (3.1.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.16.1->flexeval) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.16.1->flexeval) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.16.1->flexeval) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai<2.0.0,>=1.16.1->flexeval) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai<2.0.0,>=1.16.1->flexeval) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.14.6->flexeval) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.14.6->flexeval) (2.0.7)\n",
            "Requirement already satisfied: wasabi<1.0.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from unidic>=1.0.2->transformers[ja,sentencepiece,torch]<5.0.0,>=4.34.1->flexeval) (0.10.1)\n",
            "Requirement already satisfied: plac<2.0.0,>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from unidic>=1.0.2->transformers[ja,sentencepiece,torch]<5.0.0,>=4.34.1->flexeval) (1.4.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<3.0.0,>=2.14.6->flexeval) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<3.0.0,>=2.14.6->flexeval) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<3.0.0,>=2.14.6->flexeval) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client<3.0.0,>=2.131.0->flexeval) (0.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install bitsandbytes flexeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9IeR52dSX8V",
        "outputId": "fd7901e4-f2a7-4f10-cffe-aad07d66e40f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Googleドライブを\"drive\"ディレクトリ以下にマウント\n",
        "drive.mount(\"drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHtmbyc1SZOG",
        "outputId": "da9a47e3-6fbd-49cf-bf19-3f91acae93ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-12 16:24:15.189685: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-12 16:24:15.209639: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-12 16:24:15.215640: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-12 16:24:15.230945: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-12 16:24:16.552519: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/*\n",
            "Vicuna Benchmark for large language models in Japanese.\n",
            "\n",
            "References:\n",
            "\n",
            "* [Data Source](https://github.com/ku-nlp/ja-vicuna-qa-benchmark)\n",
            "*/\n",
            "{\n",
            "  class_path: 'ChatResponse',\n",
            "  init_args: {\n",
            "    eval_dataset: {\n",
            "      class_path: 'ChatbotBench',\n",
            "      init_args: {\n",
            "        path_or_name: 'vicuna-ja',\n",
            "        ref_path_or_name: 'vicuna-ja-ref-gpt4',\n",
            "      },\n",
            "    },\n",
            "    metrics: [\n",
            "      { class_path: 'OutputLengthStats' },\n",
            "    ],\n",
            "    gen_kwargs: { max_new_tokens: 1024 },\n",
            "    batch_size: 4,\n",
            "  },\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "!flexeval_presets vicuna-ja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4zGtIRVSbJm",
        "outputId": "31815cd3-6c9e-4101-9c7c-55e23668db76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-12 16:29:41.125397: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-12 16:29:41.145359: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-12 16:29:41.151513: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-12 16:29:41.165973: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-12 16:29:42.507183: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[32m2024-08-12 16:29:44.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.scripts.flexeval_lm\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m143\u001b[0m - \u001b[1mNamespace(eval_setup=Namespace(class_path='flexeval.ChatResponse', init_args=Namespace(eval_dataset=Namespace(class_path='flexeval.ChatbotBench', init_args=Namespace(path_or_name='vicuna-ja', ref_path_or_name='vicuna-ja-ref-gpt4', need_ref_categories=None)), gen_kwargs={'max_new_tokens': 1024}, few_shot_generator=None, metrics=[Namespace(class_path='flexeval.OutputLengthStats')], batch_size=1, max_instances=None)), eval_setups=None, save_dir='drive/MyDrive/llm_book/eval/vicuna-ja/swallow', force=False, result_recorder=None, config=None, metadata={}, language_model=Namespace(class_path='flexeval.HuggingFaceLM', init_args=Namespace(model='tokyotech-llm/Swallow-7b-instruct-v0.1', model_kwargs={'load_in_4bit': True}, tokenizer=None, tokenizer_kwargs=None, add_special_tokens=False, amp_dtype=None, random_seed=42, load_peft=False, custom_chat_template=None)))\u001b[0m\n",
            "\u001b[32m2024-08-12 16:29:44.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.scripts.flexeval_lm\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m144\u001b[0m - \u001b[1mflexeval version: 0.6.1\u001b[0m\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "Loading checkpoint shards: 100% 3/3 [01:00<00:00, 20.08s/it]\n",
            "\u001b[32m2024-08-12 16:30:46.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.core.language_model.hf_lm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m213\u001b[0m - \u001b[1mmodel device: cuda:0\u001b[0m\n",
            "\u001b[32m2024-08-12 16:30:46.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.core.language_model.hf_lm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m214\u001b[0m - \u001b[1mmodel dtype: torch.bfloat16\u001b[0m\n",
            "\u001b[32m2024-08-12 16:30:46.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.core.language_model.hf_lm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mamp_dtype: None\u001b[0m\n",
            "\u001b[32m2024-08-12 16:30:46.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.core.language_model.hf_lm\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m216\u001b[0m - \u001b[1mrandom seed: 42\u001b[0m\n",
            "\u001b[32m2024-08-12 16:30:46.902\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.scripts.flexeval_lm\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mEvaluating with the setup: {'class_path': 'flexeval.ChatResponse', 'init_args': {'eval_dataset': {'class_path': 'flexeval.ChatbotBench', 'init_args': {'path_or_name': 'vicuna-ja', 'ref_path_or_name': 'vicuna-ja-ref-gpt4', 'need_ref_categories': None}}, 'gen_kwargs': {'max_new_tokens': 1024}, 'few_shot_generator': None, 'metrics': [{'class_path': 'flexeval.OutputLengthStats'}], 'batch_size': 1, 'max_instances': None}}\u001b[0m\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "\u001b[32m2024-08-12 16:30:47.394\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.core.result_recorder.local_recorder\u001b[0m:\u001b[36mrecord_config\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mSaved the config to drive/MyDrive/llm_book/eval/vicuna-ja/swallow/config.json\u001b[0m\n",
            "\u001b[32m2024-08-12 16:30:47.394\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.core.evaluate_chat_response\u001b[0m:\u001b[36mevaluate_chat_response\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mEvaluate the model with gen_kwargs: {'max_new_tokens': 1024}\u001b[0m\n",
            "  0% 0/80 [00:00<?, ?it/s]\u001b[32m2024-08-12 16:31:09.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.core.evaluate_chat_response\u001b[0m:\u001b[36mevaluate_chat_response\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mExample of the conversation\u001b[0m\n",
            "\u001b[32m2024-08-12 16:31:09.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.core.evaluate_chat_response\u001b[0m:\u001b[36mevaluate_chat_response\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1m[{'role': 'user', 'content': '時間管理能力を向上させるにはどうしたらいいですか？'}, {'role': 'assistant', 'content': '時間管理能力を向上させるには、以下の Tips をお勧めします。➖\\n\\n1. 目標を設定する: 明確な目標を設定することで、時間をより効率的に使うことができます。\\n2. 時間を計画する: タスクを時間単位で計画し、優先順位をつけることをお勧めします。\\n3. 時間を測定する: タイマーやスマートフォンアプリなどを使って、時間を測定することをお勧めします。\\n4. 時間を節約する: 移動中に音楽を聴く代わりに、音声学習をするなど、時間を節約する方法を見つけてみてください。\\n5. 時間を管理する: 時間を管理するために、カレンダーやタスク管理ツールを使用することをお勧めします。\\n6. 時間を効率的に使う: 時間を効率的に使うために、ショートカットキーや自動化などのツールを使用することをお勧めします。\\n7. 時間を共有する: 家族や友人と時間を共有することで、時間をより有効に使うことができます。\\n\\n時間管理能力を向上させるためには、継続的な練習と習慣化が必要です。上記の Tips を実践し、時間をより効率的に使うことができます。'}]\u001b[0m\n",
            "100% 80/80 [40:17<00:00, 30.22s/it]\n",
            "\u001b[32m2024-08-12 17:11:05.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.core.evaluate_chat_response\u001b[0m:\u001b[36mevaluate_chat_response\u001b[0m:\u001b[36m111\u001b[0m - \u001b[1m{'avg_output_length': 790.2625, 'max_output_length': 2622, 'min_output_length': 170}\u001b[0m\n",
            "\u001b[32m2024-08-12 17:11:05.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.scripts.flexeval_lm\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mElapsed time: 2417.87 sec\u001b[0m\n",
            "\u001b[32m2024-08-12 17:11:05.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.core.result_recorder.local_recorder\u001b[0m:\u001b[36mrecord_metrics\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mSaved the metrics to drive/MyDrive/llm_book/eval/vicuna-ja/swallow/metrics.json\u001b[0m\n",
            "\u001b[32m2024-08-12 17:11:05.278\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.core.result_recorder.local_recorder\u001b[0m:\u001b[36mrecord_model_outputs\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mSaved the outputs to drive/MyDrive/llm_book/eval/vicuna-ja/swallow/outputs.jsonl\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!flexeval_lm \\\n",
        "  --language_model HuggingFaceLM \\\n",
        "  --language_model.model \"tokyotech-llm/Swallow-7b-instruct-v0.1\" \\\n",
        "  --language_model.model_kwargs.load_in_4bit true \\\n",
        "  --eval_setup \"vicuna-ja\" \\\n",
        "  --eval_setup.batch_size 1 \\\n",
        "  --save_dir \"drive/MyDrive/llm_book/eval/vicuna-ja/swallow\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-IZe4QlbFh_",
        "outputId": "c82ff584-98a4-4119-fc3c-0cbff6720214"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: OPENAI_API_KEY=sk-...\n"
          ]
        }
      ],
      "source": [
        "%env OPENAI_API_KEY=sk-..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FedOL8s0kwEw",
        "outputId": "b51fdb6a-cd18-49e1-efe1-55091582122b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-12 17:11:54.780678: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-12 17:11:54.800782: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-12 17:11:54.807229: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-12 17:11:54.823967: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-12 17:11:56.649434: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[32m2024-08-12 17:11:59.514\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.scripts.flexeval_lm\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m143\u001b[0m - \u001b[1mNamespace(eval_setup=Namespace(class_path='flexeval.ChatResponse', init_args=Namespace(eval_dataset=Namespace(class_path='flexeval.ChatbotBench', init_args=Namespace(path_or_name='vicuna-ja', ref_path_or_name='vicuna-ja-ref-gpt4', need_ref_categories=None)), gen_kwargs={'max_new_tokens': 1024}, few_shot_generator=None, metrics=[Namespace(class_path='flexeval.OutputLengthStats')], batch_size=4, max_instances=None)), eval_setups=None, save_dir='drive/MyDrive/llm_book/eval/vicuna-ja/gpt_3_5', force=False, result_recorder=None, config=None, metadata={}, language_model=Namespace(class_path='flexeval.OpenAIChatAPI', init_args=Namespace(model='gpt-3.5-turbo-0125', api_headers=None)))\u001b[0m\n",
            "\u001b[32m2024-08-12 17:11:59.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.scripts.flexeval_lm\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m144\u001b[0m - \u001b[1mflexeval version: 0.6.1\u001b[0m\n",
            "\u001b[32m2024-08-12 17:11:59.573\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.scripts.flexeval_lm\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mEvaluating with the setup: {'class_path': 'flexeval.ChatResponse', 'init_args': {'eval_dataset': {'class_path': 'flexeval.ChatbotBench', 'init_args': {'path_or_name': 'vicuna-ja', 'ref_path_or_name': 'vicuna-ja-ref-gpt4', 'need_ref_categories': None}}, 'gen_kwargs': {'max_new_tokens': 1024}, 'few_shot_generator': None, 'metrics': [{'class_path': 'flexeval.OutputLengthStats'}], 'batch_size': 4, 'max_instances': None}}\u001b[0m\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "\u001b[32m2024-08-12 17:11:59.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.core.result_recorder.local_recorder\u001b[0m:\u001b[36mrecord_config\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mSaved the config to drive/MyDrive/llm_book/eval/vicuna-ja/gpt_3_5/config.json\u001b[0m\n",
            "\u001b[32m2024-08-12 17:11:59.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.core.evaluate_chat_response\u001b[0m:\u001b[36mevaluate_chat_response\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mEvaluate the model with gen_kwargs: {'max_new_tokens': 1024}\u001b[0m\n",
            "  0% 0/80 [00:00<?, ?it/s]\u001b[32m2024-08-12 17:12:08.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.core.evaluate_chat_response\u001b[0m:\u001b[36mevaluate_chat_response\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mExample of the conversation\u001b[0m\n",
            "\u001b[32m2024-08-12 17:12:08.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.core.evaluate_chat_response\u001b[0m:\u001b[36mevaluate_chat_response\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1m[{'role': 'user', 'content': '時間管理能力を向上させるにはどうしたらいいですか？'}, {'role': 'assistant', 'content': '時間管理能力を向上させるためには、以下のような方法が有効です。\\n\\n1. 目標設定：具体的な目標を設定し、それに向かって計画を立てることが大切です。目標が明確であれば、時間を有効に使うことができます。\\n\\n2. 優先順位の設定：やるべきことの重要度や緊急度に応じて優先順位をつけることで、効率的に時間を使うことができます。\\n\\n3. スケジュール管理：日々の予定をスケジュールにまとめて、時間を有効に使えるようにしましょう。また、余裕を持ってスケジュールを組むことも大切です。\\n\\n4. 集中力の養成：タスクに集中し、集中力を高めることで、作業効率が高まります。集中できる環境を整えることも重要です。\\n\\n5. タイムマネジメントのツールの活用：タイマーやカレンダーアプリ、ToDoリストなどのツールを活用して、時間管理をサポートすることが役立ちます。\\n\\n6. 時間の使い方を見直す：時間の無駄遣いをしていないか、何にどれだけ時間を使っているかを振り返り、効率的に時間を使えるように改善していきましょう。\\n\\nこれらの方法を実践することで、時間管理能力を向上させることができます。'}]\u001b[0m\n",
            "100% 80/80 [03:06<00:00,  2.33s/it]\n",
            "\u001b[32m2024-08-12 17:15:06.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.core.evaluate_chat_response\u001b[0m:\u001b[36mevaluate_chat_response\u001b[0m:\u001b[36m111\u001b[0m - \u001b[1m{'avg_output_length': 406.1875, 'max_output_length': 910, 'min_output_length': 78}\u001b[0m\n",
            "\u001b[32m2024-08-12 17:15:06.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.scripts.flexeval_lm\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mElapsed time: 186.66 sec\u001b[0m\n",
            "\u001b[32m2024-08-12 17:15:06.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.core.result_recorder.local_recorder\u001b[0m:\u001b[36mrecord_metrics\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mSaved the metrics to drive/MyDrive/llm_book/eval/vicuna-ja/gpt_3_5/metrics.json\u001b[0m\n",
            "\u001b[32m2024-08-12 17:15:06.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.core.result_recorder.local_recorder\u001b[0m:\u001b[36mrecord_model_outputs\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mSaved the outputs to drive/MyDrive/llm_book/eval/vicuna-ja/gpt_3_5/outputs.jsonl\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!flexeval_lm \\\n",
        "  --language_model OpenAIChatAPI \\\n",
        "  --language_model.model \"gpt-3.5-turbo-0125\" \\\n",
        "  --eval_setup \"vicuna-ja\" \\\n",
        "  --save_dir \"drive/MyDrive/llm_book/eval/vicuna-ja/gpt_3_5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkBle7fzkx3q",
        "outputId": "5e627836-6031-44a1-f48c-acb6173069ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-12 17:20:30.202686: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-12 17:20:30.222202: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-12 17:20:30.228805: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-12 17:20:30.243284: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-12 17:20:31.485160: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/*\n",
            "This is a configuration for evaluting the quality of responses generated by an AI assistant.\n",
            "Originally used to generate scores for the Japanese versions of MT-bench or Vicuna-bench.\n",
            "\n",
            "Translated and adapted from [lm-sys/FastChat](https://github.com/lm-sys/FastChat/blob/main/fastchat/llm_judge/data/judge_prompts.jsonl).\n",
            "*/\n",
            "{\n",
            "  class_path: 'ChatLLMPairwiseJudge',\n",
            "  init_args: {\n",
            "    language_model: { class_path: 'OpenAIChatAPI', init_args: { model: 'gpt-4-turbo-2024-04-09' } },\n",
            "    prompt_template: {\n",
            "      class_path: 'Jinja2PromptTemplate',\n",
            "      init_args: {\n",
            "        template: std.stripChars(|||\n",
            "          {% set question = model1_item[\"task_inputs\"][\"messages\"][0][\"content\"] -%}\n",
            "          {% set model1_messages = model1_item[\"task_inputs\"][\"messages\"] -%}\n",
            "          {% set model2_messages = model2_item[\"task_inputs\"][\"messages\"] -%}\n",
            "\n",
            "          [ユーザの質問]\n",
            "          {{ question }}\n",
            "\n",
            "          {% if references|length > 0 -%}\n",
            "          [参考回答の開始]\n",
            "          {{ references[0] }}\n",
            "          [参考回答の終了]\n",
            "          {% endif -%}\n",
            "          [アシスタント1の回答開始]\n",
            "          {% if model1_messages|length == 1 %}{{ model1_item[\"lm_output\"] }}{% else %}{{ model1_messages[1][\"content\"] }}{% endif %}\n",
            "          [アシスタント1の回答終了]\n",
            "          [アシスタント2の回答開始]\n",
            "          {% if model2_messages|length == 1 %}{{ model2_item[\"lm_output\"] }}{% else %}{{ model2_messages[1][\"content\"] }}{% endif %}\n",
            "          [アシスタント2の回答終了]\n",
            "        |||, '\\n'),\n",
            "      },\n",
            "    },\n",
            "    system_message: {\n",
            "      class_path: 'Jinja2PromptTemplate',\n",
            "      init_args: {\n",
            "        template: std.stripChars(|||\n",
            "          {% if references|length > 0 -%}\n",
            "          あなたは、回答の質をチェックするための審判員です。以下に示されるユーザーの質問に対する2つのAIアシスタントの応答の品質を評価してください。回答の内容がユーザーの指示に従っており、ユーザーの質問によりよく答えているアシスタントを選んでください。参照回答、アシスタント1の回答、アシスタント2の回答が与えられるので、どちらのアシスタントの回答が優れているかを評価してください。評価の際には、まずそれぞれのアシスタントの回答を参照回答と比較し、回答の誤りを見つけて修正してください。立場が偏らないようにし、回答の提示順があなたの判断に影響しないようにしてください。回答の長さが評価に影響しないこと、特定のアシスタントの名前を好まないこと、できるだけ客観的であること、に気をつけてください。説明の後に、最終的な判断を以下の形式に従って出力してください：アシスタント1が優れていれば[[1]]、アシスタント2が優れていれば[[2]]、同点の場合は[[3]]\n",
            "          {%- else -%}\n",
            "          あなたは、回答の質をチェックするための審判員です。以下に示されるユーザーの質問に対する2つのAIアシスタントの応答の品質を評価してください。回答の内容がユーザーの指示に従っており、ユーザーの質問によりよく答えているアシスタントを選んでください。具体的には、回答の有用性、関連性、正確性、深さ、創造性、詳細レベルなどの要素を考慮する必要があります。評価の際には、まず2つの回答を比較し、簡単な説明をしてください。立場が偏らないようにし、回答の提示順があなたの判断に影響しないようにしてください。回答の長さが評価に影響しないこと、特定のアシスタントの名前を好まないこと、できるだけ客観的であること、に気をつけてください。説明の後に、最終的な判断を以下の形式に従って出力してください：アシスタント1が優れていれば[[1]]、アシスタント2が優れていれば[[2]]、同点の場合は[[3]]\n",
            "          {%- endif %}\n",
            "        |||, '\\n'),\n",
            "      },\n",
            "    },\n",
            "  },\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "!flexeval_presets assistant_judge_ja_single_turn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3yNxAExmvXt",
        "outputId": "c58fb6f7-9daf-4fdb-ccd0-573603c4b641"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-12 17:20:58.781219: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-12 17:20:58.801208: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-12 17:20:58.807333: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-12 17:20:58.822112: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-12 17:21:00.058237: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[32m2024-08-12 17:21:02.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.scripts.flexeval_pairwise\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mNamespace(lm_output_paths={'swallow': 'drive/MyDrive/llm_book/eval/vicuna-ja/swallow/outputs.jsonl', 'gpt_3_5': 'drive/MyDrive/llm_book/eval/vicuna-ja/gpt_3_5/outputs.jsonl'}, judge=Namespace(class_path='flexeval.ChatLLMPairwiseJudge', init_args=Namespace(language_model=Namespace(class_path='flexeval.OpenAIChatAPI', init_args=Namespace(model='gpt-4-turbo-2024-04-09', api_headers=None)), prompt_template=Namespace(class_path='flexeval.Jinja2PromptTemplate', init_args=Namespace(template='{% set question = model1_item[\"task_inputs\"][\"messages\"][0][\"content\"] -%}\\n{% set model1_messages = model1_item[\"task_inputs\"][\"messages\"] -%}\\n{% set model2_messages = model2_item[\"task_inputs\"][\"messages\"] -%}\\n\\n[ユーザの質問]\\n{{ question }}\\n\\n{% if references|length > 0 -%}\\n[参考回答の開始]\\n{{ references[0] }}\\n[参考回答の終了]\\n{% endif -%}\\n[アシスタント1の回答開始]\\n{% if model1_messages|length == 1 %}{{ model1_item[\"lm_output\"] }}{% else %}{{ model1_messages[1][\"content\"] }}{% endif %}\\n[アシスタント1の回答終了]\\n[アシスタント2の回答開始]\\n{% if model2_messages|length == 1 %}{{ model2_item[\"lm_output\"] }}{% else %}{{ model2_messages[1][\"content\"] }}{% endif %}\\n[アシスタント2の回答終了]')), system_message=Namespace(class_path='flexeval.Jinja2PromptTemplate', init_args=Namespace(template='{% if references|length > 0 -%}\\nあなたは、回答の質をチェックするための審判員です。以下に示されるユーザーの質問に対する2つのAIアシスタントの応答の品質を評価してください。回答の内容がユーザーの指示に従っており、ユーザーの質問によりよく答えているアシスタントを選んでください。参照回答、アシスタント1の回答、アシスタント2の回答が与えられるので、どちらのアシスタントの回答が優れているかを評価してください。評価の際には、まずそれぞれのアシスタントの回答を参照回答と比較し、回答の誤りを見つけて修正してください。立場が偏らないようにし、回答の提示順があなたの判断に影響しないようにしてください。回答の長さが評価に影響しないこと、特定のアシスタントの名前を好まないこと、できるだけ客観的であること、に気をつけてください。説明の後に、最終的な判断を以下の形式に従って出力してください：アシスタント1が優れていれば[[1]]、アシスタント2が優れていれば[[2]]、同点の場合は[[3]]\\n{%- else -%}\\nあなたは、回答の質をチェックするための審判員です。以下に示されるユーザーの質問に対する2つのAIアシスタントの応答の品質を評価してください。回答の内容がユーザーの指示に従っており、ユーザーの質問によりよく答えているアシスタントを選んでください。具体的には、回答の有用性、関連性、正確性、深さ、創造性、詳細レベルなどの要素を考慮する必要があります。評価の際には、まず2つの回答を比較し、簡単な説明をしてください。立場が偏らないようにし、回答の提示順があなたの判断に影響しないようにしてください。回答の長さが評価に影響しないこと、特定のアシスタントの名前を好まないこと、できるだけ客観的であること、に気をつけてください。説明の後に、最終的な判断を以下の形式に従って出力してください：アシスタント1が優れていれば[[1]]、アシスタント2が優れていれば[[2]]、同点の場合は[[3]]\\n{%- endif %}')))), match_maker=Namespace(class_path='flexeval.AllCombinations', init_args=Namespace(include_reversed=True)), scorers=[Namespace(class_path='flexeval.WinRateScorer'), Namespace(class_path='flexeval.BradleyTerryScorer', init_args=Namespace(max_iters=1000, error_tol=0.001, eps=1e-08, base=10.0, scale=400.0, init_rating=1000.0))], batch_size=4, previous_outputs_path=None, save_dir='drive/MyDrive/llm_book/eval/vicuna-ja/judgement', force=False, result_recorder=None, config=None, metadata={})\u001b[0m\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "\u001b[32m2024-08-12 17:21:02.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.scripts.flexeval_pairwise\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mflexeval version: 0.6.1\u001b[0m\n",
            "\u001b[32m2024-08-12 17:21:02.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.core.result_recorder.local_recorder\u001b[0m:\u001b[36mrecord_config\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mSaved the config to drive/MyDrive/llm_book/eval/vicuna-ja/judgement/config.json\u001b[0m\n",
            "\u001b[32m2024-08-12 17:37:33.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.core.pairwise_comparison.scorer.bradley_terry\u001b[0m:\u001b[36mcompute_scores\u001b[0m:\u001b[36m85\u001b[0m - \u001b[1m * Converged after 1 iterations.\u001b[0m\n",
            "\u001b[32m2024-08-12 17:37:33.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.core.evaluate_pairwise\u001b[0m:\u001b[36mevaluate_pairwise\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mnewly judged: 160 items, loaded from cache: 0 items\u001b[0m\n",
            "\u001b[32m2024-08-12 17:37:33.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.core.evaluate_pairwise\u001b[0m:\u001b[36mevaluate_pairwise\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1m{'win_rate': {'gpt_3_5': 73.75, 'swallow': 26.25}, 'bradley_terry': {'gpt_3_5': 1089.7265433983746, 'swallow': 910.2734566016254}}\u001b[0m\n",
            "\u001b[32m2024-08-12 17:37:33.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.scripts.flexeval_pairwise\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1mElapsed time: 990.9048530869995\u001b[0m\n",
            "\u001b[32m2024-08-12 17:37:33.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.core.result_recorder.local_recorder\u001b[0m:\u001b[36mrecord_metrics\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mSaved the metrics to drive/MyDrive/llm_book/eval/vicuna-ja/judgement/metrics.json\u001b[0m\n",
            "\u001b[32m2024-08-12 17:37:33.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mflexeval.core.result_recorder.local_recorder\u001b[0m:\u001b[36mrecord_model_outputs\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mSaved the outputs to drive/MyDrive/llm_book/eval/vicuna-ja/judgement/outputs.jsonl\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!flexeval_pairwise \\\n",
        "  --lm_output_paths.swallow \"drive/MyDrive/llm_book/eval/vicuna-ja/swallow/outputs.jsonl\"  \\\n",
        "  --lm_output_paths.gpt_3_5 \"drive/MyDrive/llm_book/eval/vicuna-ja/gpt_3_5/outputs.jsonl\"  \\\n",
        "  --judge \"assistant_judge_ja_single_turn\" \\\n",
        "  --save_dir \"drive/MyDrive/llm_book/eval/vicuna-ja/judge\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"win_rate\": {\n",
            "        \"gpt_3_5\": 73.75,\n",
            "        \"swallow\": 26.25\n",
            "    },\n",
            "    \"bradley_terry\": {\n",
            "        \"gpt_3_5\": 1089.7265433983746,\n",
            "        \"swallow\": 910.2734566016254\n",
            "    },\n",
            "    \"elapsed_time\": 990.9048530869995\n",
            "}"
          ]
        }
      ],
      "source": [
        "!cat ./drive/MyDrive/llm_book/eval/vicuna-ja/judge/metrics.json"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}